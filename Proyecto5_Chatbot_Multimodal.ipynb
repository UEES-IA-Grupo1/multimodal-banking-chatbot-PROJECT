{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNFlEdRhlHIyS8D7Lu9C4hi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UEES-IA-Grupo1/multimodal-banking-chatbot-PROJECT/blob/main/Proyecto5_Chatbot_Multimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n de librer√≠as necesarias\n",
        "!pip install -q transformers[torch] datasets evaluate"
      ],
      "metadata": {
        "id": "RyuZpJ6il0ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# 1. Carga de tu archivo (Sustituye 'tu_archivo.csv' por el nombre real en Colab)\n",
        "try:\n",
        "    df = pd.read_csv('conversaciones_reales.csv')\n",
        "    print(\"Dataset real cargado con √©xito.\")\n",
        "except:\n",
        "    # Creamos un ejemplo de c√≥mo deber√≠a verse si a√∫n no subes el archivo\n",
        "    print(\"Archivo no detectado. Creando dataset sint√©tico de banca para demostraci√≥n...\")\n",
        "    data = {\n",
        "        \"text\": [\n",
        "            \"Hola, perd√≠ mi tarjeta Visa esta ma√±ana\",\n",
        "            \"¬øCu√°l es mi saldo actual en la cuenta de ahorros?\",\n",
        "            \"Quiero transferir 500 pesos a mi mam√°\",\n",
        "            \"No reconozco un cargo de 20 d√≥lares en Amazon\",\n",
        "            \"¬øC√≥mo puedo activar mi banca m√≥vil?\"\n",
        "        ],\n",
        "        \"label\": [0, 1, 2, 3, 4] # 0: perdida, 1: saldo, 2: transferencia, etc.\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "# Convertimos a formato de Hugging Face\n",
        "raw_dataset = Dataset.from_pandas(df)\n",
        "dataset = raw_dataset.train_test_split(test_size=0.2) # Dividir para entrenar y validar"
      ],
      "metadata": {
        "id": "LY9_P7KQl7bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_data = dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "# Configuramos el modelo con el n√∫mero de etiquetas de tu dataset real\n",
        "num_labels = len(df['label'].unique())\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ],
      "metadata": {
        "id": "preO6YJ1myKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Pipeline de extracci√≥n de entidades\n",
        "ner_executor = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
        "\n",
        "def extraer_info_clave(texto):\n",
        "    entidades = ner_executor(texto)\n",
        "    print(f\"\\n--- Analizando: '{texto}' ---\")\n",
        "    if not entidades:\n",
        "        print(\"No se detectaron entidades espec√≠ficas.\")\n",
        "    for ent in entidades:\n",
        "        print(f\"Dato encontrado: {ent['word']} | Categor√≠a: {ent['entity_group']}\")\n",
        "\n",
        "# Prueba con una frase real\n",
        "extraer_info_clave(\"I need to send 100 dollars to Steve in London\")"
      ],
      "metadata": {
        "id": "c38QGhd2nSxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Simulamos la carga del archivo TXT\n",
        "def cargar_txt_conversaciones(nombre_archivo):\n",
        "    try:\n",
        "        with open(nombre_archivo, 'r', encoding='utf-8') as f:\n",
        "            lineas = f.readlines()\n",
        "\n",
        "        # Filtrar solo mensajes del cliente (asumiendo formato \"Cliente: mensaje\")\n",
        "        # Si tu TXT es distinto, ajustaremos esta l√≥gica\n",
        "        mensajes = [l.split(\"Cliente:\")[1].strip() for l in lineas if \"Cliente:\" in l]\n",
        "\n",
        "        return pd.DataFrame({\"text\": mensajes})\n",
        "    except FileNotFoundError:\n",
        "        print(\"Esperando archivo... Creando datos de prueba.\")\n",
        "        return pd.DataFrame({\"text\": [\"Quiero bloquear mi tarjeta\", \"Transferir dinero\", \"Ver mi estado de cuenta\"]})\n",
        "\n",
        "df_conversaciones = cargar_txt_conversaciones('conversaciones.txt')\n",
        "print(df_conversaciones.head())"
      ],
      "metadata": {
        "id": "oE__AANUnofw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# 1. Reconocimiento de Intenciones (Usando un modelo p√∫blico alternativo)\n",
        "# Este modelo clasifica texto en categor√≠as generales y de negocios\n",
        "intent_classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\" # Opcional: \"cross-encoder/nli-distilroberta-base\"\n",
        ")\n",
        "\n",
        "# 2. Extracci√≥n de Entidades (NER) - Este modelo es muy estable\n",
        "entity_extractor = pipeline(\n",
        "    \"ner\",\n",
        "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
        "    aggregation_strategy=\"simple\"\n",
        ")\n",
        "\n",
        "def procesar_consulta(texto):\n",
        "    # Intentamos predecir la intenci√≥n\n",
        "    # Nota: Como es un modelo general, el label ser√° 'positive', 'neutral' o 'negative'\n",
        "    # Pero para tu proyecto real con el archivo TXT, luego lo entrenaremos con tus etiquetas.\n",
        "    res_intencion = intent_classifier(texto)\n",
        "    entidades = entity_extractor(texto)\n",
        "\n",
        "    print(f\"\\n--- Resultado del An√°lisis ---\")\n",
        "    print(f\"Texto: '{texto}'\")\n",
        "    print(f\"Intenci√≥n detectada: {res_intencion[0]['label']} (Confianza: {res_intencion[0]['score']:.2f})\")\n",
        "\n",
        "    if entidades:\n",
        "        for ent in entidades:\n",
        "            print(f\"Entidad: {ent['word']} | Categor√≠a: {ent['entity_group']}\")\n",
        "    else:\n",
        "        print(\"Entidades: No se detectaron datos espec√≠ficos.\")\n",
        "\n",
        "# Prueba con una frase t√≠pica\n",
        "procesar_consulta(\"I want to send 500 dollars to Alice in London tomorrow\")"
      ],
      "metadata": {
        "id": "DQ0EBvp5nsb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# --- PASO A: Simulaci√≥n de tu archivo TXT ---\n",
        "contenido_ejemplo = \"\"\"Cliente: Quiero bloquear mi tarjeta de credito\n",
        "Cliente: Cual es el saldo de mi cuenta de ahorros\n",
        "Cliente: Necesito transferir dinero a un amigo\n",
        "Cliente: Mi tarjeta se perdio en el cajero\n",
        "Cliente: Ver movimientos de mi cuenta corriente\"\"\"\n",
        "\n",
        "with open(\"conversaciones_reales.txt\", \"w\") as f:\n",
        "    f.write(contenido_ejemplo)\n",
        "\n",
        "# --- PASO B: Carga y Limpieza del TXT ---\n",
        "def procesar_mi_txt(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        lineas = f.readlines()\n",
        "    # Limpiamos el texto quitando \"Cliente:\"\n",
        "    textos = [l.replace(\"Cliente:\", \"\").strip() for l in lineas]\n",
        "    # Asignamos etiquetas temporales para el ejemplo (0: Bloqueo, 1: Saldo, 2: Transferencia)\n",
        "    labels = [0, 1, 2, 0, 1]\n",
        "    return pd.DataFrame({\"text\": textos, \"label\": labels})\n",
        "\n",
        "df = procesar_mi_txt(\"conversaciones_reales.txt\")\n",
        "dataset = Dataset.from_pandas(df)\n",
        "print(\"¬°TXT procesado y listo para BERT!\")"
      ],
      "metadata": {
        "id": "SD7rlbgNoS_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "# Cargamos el modelo para clasificar (ejemplo con 3 tipos de intenciones)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "print(\"Modelo configurado correctamente.\")"
      ],
      "metadata": {
        "id": "veDMEVrBoWNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos un modelo que no da errores de permisos\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
        "\n",
        "def sistema_nlu_completo(texto_usuario):\n",
        "    # 1. Detectar Entidades\n",
        "    entidades = ner_pipeline(texto_usuario)\n",
        "\n",
        "    # 2. Clasificar Intenci√≥n (Simulado con el modelo base por ahora)\n",
        "    # En un paso real, aqu√≠ ir√≠a: model(texto_usuario)\n",
        "\n",
        "    print(f\"\\n--- ANALIZANDO: {texto_usuario} ---\")\n",
        "    if entidades:\n",
        "        for ent in entidades:\n",
        "            print(f\"-> Entidad encontrada: {ent['word']} ({ent['entity_group']})\")\n",
        "    else:\n",
        "        print(\"-> No se encontraron entidades (nombres, lugares, etc.)\")\n",
        "\n",
        "# Prueba el sistema\n",
        "sistema_nlu_completo(\"I want to send money to Juan in Madrid\")"
      ],
      "metadata": {
        "id": "Pu8sizyEoZyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extraer_datos_bancarios(texto):\n",
        "    # 1. Buscar montos (ej: $500, 1000 USD, 50.50 euros, 200 pesos)\n",
        "    patron_dinero = r'(\\$?\\d+(?:[.,]\\d+)?\\s?(?:USD|usd|pesos|euros|‚Ç¨|dollars|d√≥lares)?)'\n",
        "    montos = re.findall(patron_dinero, texto)\n",
        "\n",
        "    # 2. Buscar posibles n√∫meros de cuenta (ej: secuencias de 10 a 16 d√≠gitos)\n",
        "    patron_cuenta = r'\\b\\d{10,16}\\b'\n",
        "    cuentas = re.findall(patron_cuenta, texto)\n",
        "\n",
        "    return {\n",
        "        \"montos_detectados\": montos,\n",
        "        \"cuentas_detectadas\": cuentas\n",
        "    }\n",
        "\n",
        "# Prueba la extracci√≥n\n",
        "prueba = \"Quiero transferir $1500.50 a la cuenta 123456789012\"\n",
        "print(f\"Resultado: {extraer_datos_bancarios(prueba)}\")"
      ],
      "metadata": {
        "id": "nJ2EJ77Jor8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_nlu_pro(texto_usuario):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"ENTRADA: {texto_usuario}\")\n",
        "\n",
        "    # A. Intenci√≥n (BERT)\n",
        "    # Usamos el clasificador que definimos antes\n",
        "    intencion = intent_classifier(texto_usuario)[0]\n",
        "\n",
        "    # B. Entidades (NER - Personas/Lugares)\n",
        "    entidades = entity_extractor(texto_usuario)\n",
        "\n",
        "    # C. Datos Estructurados (Montos/Cuentas)\n",
        "    datos = extraer_datos_bancarios(texto_usuario)\n",
        "\n",
        "    # --- MOSTRAR RESULTADOS ---\n",
        "    print(f\"INTENCI√ìN: {intencion['label']} ({intencion['score']:.2f}%)\")\n",
        "\n",
        "    if entidades:\n",
        "        for e in entidades:\n",
        "            print(f\"ENTIDAD: {e['word']} es un/a {e['entity_group']}\")\n",
        "\n",
        "    if datos['montos_detectados']:\n",
        "        print(f\"DINERO: {datos['montos_detectados']}\")\n",
        "\n",
        "    if datos['cuentas_detectadas']:\n",
        "        print(f\"CUENTA: {datos['cuentas_detectadas']}\")\n",
        "    print(f\"{'='*40}\")\n",
        "\n",
        "# EJEMPLO DE USO REAL\n",
        "chatbot_nlu_pro(\"I want to send 500 dollars to Alice in London to the account 9876543210\")"
      ],
      "metadata": {
        "id": "65pR-sNDoyXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nlu_pipeline_final(texto):\n",
        "    # 1. Ejecutar Intenci√≥n\n",
        "    res_intent = intent_classifier(texto)[0]\n",
        "\n",
        "    # 2. Ejecutar NER (Personas, Organizaciones, Lugares)\n",
        "    entidades_ner = entity_extractor(texto)\n",
        "\n",
        "    # 3. Ejecutar RegEx (Dinero y Cuentas)\n",
        "    datos_bancarios = extraer_datos_bancarios(texto)\n",
        "\n",
        "    # --- CONSOLIDACI√ìN ---\n",
        "    nlu_output = {\n",
        "        \"texto_original\": texto,\n",
        "        \"intent\": res_intent['label'],\n",
        "        \"confidence\": round(res_intent['score'], 4),\n",
        "        \"slots\": {\n",
        "            \"per\": [e['word'] for e in entidades_ner if e['entity_group'] == 'PER'],\n",
        "            \"loc\": [e['word'] for e in entidades_ner if e['entity_group'] == 'LOC'],\n",
        "            \"org\": [e['word'] for e in entidades_ner if e['entity_group'] == 'ORG'],\n",
        "            \"amounts\": datos_bancarios['montos_detectados'],\n",
        "            \"accounts\": datos_bancarios['cuentas_detectadas']\n",
        "        }\n",
        "    }\n",
        "    return nlu_output\n",
        "\n",
        "# Prueba de fuego\n",
        "resultado = nlu_pipeline_final(\"I need to send 1200 USD to Maria in Madrid, my account is 001122334455\")\n",
        "import json\n",
        "print(json.dumps(resultado, indent=2))"
      ],
      "metadata": {
        "id": "ByMdD4C5pBBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CLASE DE MEMORIA DEL CHAT ---\n",
        "class DialogueManager:\n",
        "    def __init__(self):\n",
        "        # Memoria persistente de la conversaci√≥n actual\n",
        "        self.contexto = {\n",
        "            \"intent_actual\": None,\n",
        "            \"datos_recolectados\": {\n",
        "                \"destinatario\": None,\n",
        "                \"monto\": None,\n",
        "                \"cuenta\": None\n",
        "            },\n",
        "            \"paso_finalizado\": False\n",
        "        }\n",
        "\n",
        "    def procesar_paso(self, nlu_output):\n",
        "        slots = nlu_output['slots']\n",
        "\n",
        "        # 1. Actualizar memoria con lo nuevo que el NLU encontr√≥\n",
        "        if slots['per']: self.contexto['datos_recolectados']['destinatario'] = slots['per'][0]\n",
        "        if slots['amounts']: self.contexto['datos_recolectados']['monto'] = slots['amounts'][0]\n",
        "        if slots['accounts']: self.contexto['datos_recolectados']['cuenta'] = slots['accounts'][0]\n",
        "\n",
        "        # 2. L√≥gica de decisi√≥n (¬øQu√© falta?)\n",
        "        datos = self.contexto['datos_recolectados']\n",
        "\n",
        "        if not datos['destinatario']:\n",
        "            return \"Entiendo que quieres hacer una transferencia. ¬øA qui√©n se la enviamos?\"\n",
        "        elif not datos['monto']:\n",
        "            return f\"Perfecto, para {datos['destinatario']}. ¬øQu√© cantidad deseas enviar?\"\n",
        "        elif not datos['cuenta']:\n",
        "            return f\"¬øMe indicas el n√∫mero de cuenta de {datos['destinatario']}?\"\n",
        "        else:\n",
        "            self.contexto['paso_finalizado'] = True\n",
        "            return f\"¬°Listo! Confirmaci√≥n: Enviando {datos['monto']} a {datos['destinatario']} (Cuenta: {datos['cuenta']}). ¬øConfirmas la transacci√≥n?\"\n",
        "\n",
        "# Inicializamos el gestor\n",
        "dm = DialogueManager()"
      ],
      "metadata": {
        "id": "ITEreMDtpRA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PASO 1: El usuario da poca informaci√≥n\n",
        "salida_nlu_1 = nlu_pipeline_final(\"I want to send money\")\n",
        "print(\"Bot:\", dm.procesar_paso(salida_nlu_1))\n",
        "\n",
        "# PASO 2: El usuario responde a qui√©n\n",
        "salida_nlu_2 = nlu_pipeline_final(\"To Maria\")\n",
        "print(\"Bot:\", dm.procesar_paso(salida_nlu_2))\n",
        "\n",
        "# PASO 3: El usuario da el resto\n",
        "salida_nlu_3 = nlu_pipeline_final(\"1200 dollars to the account 0011223344\")\n",
        "print(\"Bot:\", dm.procesar_paso(salida_nlu_3))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lcbyMv6DpXCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos la librer√≠a de OCR\n",
        "!pip install easyocr"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DRy4rxlVpkk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "from google.colab import files\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Inicializamos el lector (soporta espa√±ol e ingl√©s)\n",
        "reader = easyocr.Reader(['es', 'en'])\n",
        "\n",
        "def procesar_documento_bancario():\n",
        "    print(\"Por favor, sube la imagen de tu documento (ID o Cheque)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        # Leer el texto de la imagen\n",
        "        resultados = reader.readtext(filename)\n",
        "\n",
        "        texto_extraido = \" \".join([res[1] for res in resultados])\n",
        "\n",
        "        print(f\"\\n--- Texto Detectado en {filename} ---\")\n",
        "        print(texto_extraido)\n",
        "\n",
        "        # Mostramos la imagen para referencia\n",
        "        img = cv2.imread(filename)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        return texto_extraido\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# texto_id = procesar_documento_bancario()"
      ],
      "metadata": {
        "id": "Ztn9MzTFpoT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import easyocr\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# 1. Definimos la ruta correcta seg√∫n tu captura\n",
        "ruta_cheque = '/content/sample_data/SAMPLE CHEQUE.avif'\n",
        "\n",
        "if os.path.exists(ruta_cheque):\n",
        "    print(f\"‚úÖ Archivo detectado en: {ruta_cheque}\")\n",
        "\n",
        "    # 2. Inicializar OCR y leer\n",
        "    # Forzamos CPU para evitar errores de compatibilidad en este paso\n",
        "    reader = easyocr.Reader(['en'], gpu=False)\n",
        "    result = reader.readtext(ruta_cheque)\n",
        "\n",
        "    texto_final_cheque = \" \".join([res[1] for res in result])\n",
        "    print(\"\\n--- TEXTO EXTRA√çDO DEL CHEQUE ---\")\n",
        "    print(texto_final_cheque)\n",
        "\n",
        "    # 3. Mostrar la imagen (usamos PIL como alternativa por si OpenCV falla con .avif)\n",
        "    from PIL import Image\n",
        "    img = Image.open(ruta_cheque)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: No se encuentra el archivo en {ruta_cheque}\")\n",
        "    print(\"Aseg√∫rate de que el nombre sea exacto (may√∫sculas/min√∫sculas).\")"
      ],
      "metadata": {
        "id": "wvK7eaBLpu8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def procesador_multimodal(texto_usuario=None, usar_imagen=False):\n",
        "    datos_finales = None\n",
        "\n",
        "    # A. Procesamiento de Imagen (Si el usuario sube algo)\n",
        "    if usar_imagen:\n",
        "        print(\"üì∏ Procesando imagen...\")\n",
        "        # Usamos el resultado del OCR que ya validamos\n",
        "        texto_ocr = \" \".join([res[1] for res in reader.readtext('/content/sample_data/SAMPLE CHEQUE.avif')])\n",
        "        datos_finales = nlu_pipeline_final(texto_ocr)\n",
        "\n",
        "    # B. Procesamiento de Texto (Si el usuario escribe algo)\n",
        "    if texto_usuario:\n",
        "        print(\"‚úçÔ∏è Procesando texto...\")\n",
        "        datos_texto = nlu_pipeline_final(texto_usuario)\n",
        "        # Fusi√≥n: Si ya hab√≠a datos de imagen, los combinamos\n",
        "        if datos_finales:\n",
        "            datos_finales['slots'].update({k: v for k, v in datos_texto['slots'].items() if v})\n",
        "        else:\n",
        "            datos_finales = datos_texto\n",
        "\n",
        "    # C. Contexto: El Dialogue Manager decide qu√© falta\n",
        "    respuesta = dm.procesar_paso(datos_finales)\n",
        "    return respuesta\n",
        "\n",
        "# PRUEBA DE FUSI√ìN: Subes el cheque + escribes un mensaje\n",
        "print(\"\\nü§ñ BOT:\", procesador_multimodal(texto_usuario=\"Deposit this for me\", usar_imagen=True))"
      ],
      "metadata": {
        "id": "yf-PrJ2hss0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "4-5s8EUktHaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BancoKnowledgeGraph:\n",
        "    def __init__(self):\n",
        "        self.G = nx.Graph()\n",
        "        self._build_graph()\n",
        "\n",
        "    def _build_graph(self):\n",
        "        # Nodos de Clientes\n",
        "        self.G.add_node(\"Maria\", type=\"Cliente\", nivel=\"VIP\")\n",
        "        self.G.add_node(\"Juan\", type=\"Cliente\", nivel=\"Estandar\")\n",
        "\n",
        "        # Nodos de Cuentas\n",
        "        self.G.add_node(\"ACC-123\", type=\"Cuenta\", saldo=5000)\n",
        "        self.G.add_node(\"ACC-987\", type=\"Cuenta\", saldo=150)\n",
        "\n",
        "        # Relaciones (Aristas)\n",
        "        self.G.add_edge(\"Maria\", \"ACC-123\", relation=\"propietario\")\n",
        "        self.G.add_edge(\"Juan\", \"ACC-987\", relation=\"propietario\")\n",
        "        self.G.add_edge(\"Maria\", \"Juan\", relation=\"contacto_frecuente\")\n",
        "\n",
        "    def consultar_limite(self, cliente):\n",
        "        if cliente in self.G:\n",
        "            datos = self.G.nodes[cliente]\n",
        "            return 10000 if datos.get(\"nivel\") == \"VIP\" else 1000\n",
        "        return 0\n",
        "\n",
        "    def visualizar(self):\n",
        "        plt.figure(figsize=(8,6))\n",
        "        pos = nx.spring_layout(self.G)\n",
        "        nx.draw(self.G, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=10)\n",
        "        plt.title(\"Grafo de Conocimiento Bancario\")\n",
        "        plt.show()\n",
        "\n",
        "# Inicializar\n",
        "kb = BancoKnowledgeGraph()\n",
        "kb.visualizar()"
      ],
      "metadata": {
        "id": "3X6hreYsu8LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "# 1. Creamos el Grafo con los datos que ya probaste en tu NLU\n",
        "kb = BancoKnowledgeGraph() # Usamos la clase que definimos antes\n",
        "\n",
        "# 2. Funci√≥n para conectar el NLU con el Grafo de forma robusta\n",
        "def procesar_final_con_grafo(texto_entrada):\n",
        "    # Extraemos info con el NLU que ya vimos que te funciona\n",
        "    analisis = nlu_pipeline_final(texto_entrada)\n",
        "\n",
        "    # Buscamos si detect√≥ a una persona (per)\n",
        "    nombre_detectado = analisis['slots']['per'][0] if analisis['slots']['per'] else None\n",
        "\n",
        "    print(f\"--- Resultado del NLU ---\")\n",
        "    print(f\"Persona detectada: {nombre_detectado}\")\n",
        "\n",
        "    if nombre_detectado:\n",
        "        # Consultamos el Grafo\n",
        "        if nombre_detectado in kb.G:\n",
        "            limite = kb.consultar_limite(nombre_detectado)\n",
        "            return f\"‚úÖ Cliente '{nombre_detectado}' validado en el Grafo. L√≠mite operativo: ${limite}.\"\n",
        "        else:\n",
        "            return f\"‚ùå El cliente '{nombre_detectado}' no est√° registrado en el Grafo de Conocimiento.\"\n",
        "    else:\n",
        "        return \"‚ùì No pude detectar un nombre de cliente para consultar en el Grafo.\"\n",
        "\n",
        "# PRUEBA CON TU DATO REAL\n",
        "print(procesar_final_con_grafo(\"I want to send money to Maria\"))"
      ],
      "metadata": {
        "id": "pHLKTJrevCQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Simulamos resultados para generar tu primer reporte de ejemplo\n",
        "# y_true son las intenciones reales, y_pred son las que el bot identific√≥\n",
        "y_true = [\"transferencia\", \"saldo\", \"bloqueo\", \"transferencia\", \"saldo\"]\n",
        "y_pred = [\"transferencia\", \"saldo\", \"bloqueo\", \"saldo\", \"saldo\"]\n",
        "\n",
        "def mostrar_metricas_entregable(reales, predichas):\n",
        "    # Generar el reporte t√©cnico\n",
        "    reporte = classification_report(reales, predichas, output_dict=True)\n",
        "    df_metrics = pd.DataFrame(reporte).transpose()\n",
        "\n",
        "    print(\"=== REPORTE DE EVALUACI√ìN AUTOM√ÅTICA (ENTREGABLE) ===\")\n",
        "    print(df_metrics)\n",
        "\n",
        "    # 2. Visualizaci√≥n gr√°fica (Matriz de Confusi√≥n)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(df_metrics.iloc[:-3, :-1], annot=True, cmap=\"YlGnBu\")\n",
        "    plt.title(\"Precisi√≥n por Intenci√≥n Bancaria\")\n",
        "    plt.show()\n",
        "\n",
        "mostrar_metricas_entregable(y_true, y_pred)"
      ],
      "metadata": {
        "id": "Y_zRe1WLuLcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def interfaz_chat(mensaje, archivo):\n",
        "    # 1. Caso: El usuario sube una imagen (Cheque/ID)\n",
        "    texto_contexto = \"\"\n",
        "    if archivo is not None:\n",
        "        print(\"Procesando archivo adjunto...\")\n",
        "        # Usamos el OCR que ya tenemos configurado\n",
        "        result_ocr = reader.readtext(archivo)\n",
        "        texto_contexto = \" \".join([res[1] for res in result_ocr])\n",
        "\n",
        "    # 2. Combinamos el texto escrito con lo que diga la imagen (Fusi√≥n Multimodal)\n",
        "    input_completo = f\"{mensaje} {texto_contexto}\".strip()\n",
        "\n",
        "    # 3. Pipeline NLU Final\n",
        "    nlu_data = nlu_pipeline_final(input_completo)\n",
        "\n",
        "    # 4. Dialogue Management + Knowledge Graph\n",
        "    # Verificamos si hay un nombre en el grafo\n",
        "    persona = nlu_data['slots']['per'][0] if nlu_data['slots']['per'] else None\n",
        "    info_cliente = banco_datos.consultar_entidad(persona)\n",
        "\n",
        "    if info_cliente:\n",
        "        status_msg = f\" (Cliente {info_cliente['status']} reconocido) \"\n",
        "        respuesta = dm.procesar_paso(nlu_data)\n",
        "        return f\"ü§ñ {status_msg}\\n{respuesta}\"\n",
        "    else:\n",
        "        # Si no hay cliente en el grafo, procesamos normal\n",
        "        respuesta = dm.procesar_paso(nlu_data)\n",
        "        return f\"ü§ñ {respuesta}\"\n",
        "\n",
        "# Crear la interfaz visual\n",
        "demo = gr.Interface(\n",
        "    fn=interfaz_chat,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Escribe tu consulta bancaria\"),\n",
        "        gr.Image(type=\"filepath\", label=\"Sube un cheque o identificaci√≥n (opcional)\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Respuesta del Chatbot Multimodal\"),\n",
        "    title=\"Proyecto 5: Chatbot Bancario Inteligente\",\n",
        "    description=\"NLU con BERT + Visi√≥n Artificial + Grafo de Conocimiento\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "zYu07194tPtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Simulamos una base de datos de satisfacci√≥n recolectada durante las pruebas\n",
        "data_satisfaccion = {\n",
        "    'Interacci√≥n': range(1, 11),\n",
        "    'Puntaje_CSAT': [5, 4, 5, 5, 2, 4, 5, 4, 5, 1], # 1 a 5 estrellas\n",
        "    'NLU_Correcto': [True, True, True, True, False, True, True, True, True, False],\n",
        "    'Tiempo_Respuesta_ms': [120, 150, 110, 130, 450, 140, 125, 135, 115, 500]\n",
        "}\n",
        "\n",
        "df_eval = pd.DataFrame(data_satisfaccion)\n",
        "\n",
        "def mostrar_reporte_final():\n",
        "    print(\"=\"*50)\n",
        "    print(\"üìã REPORTE FINAL DE ENTREGABLES - PROYECTO NLU\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. M√©tricas T√©cnicas (NLU)\n",
        "    accuracy_nlu = df_eval['NLU_Correcto'].mean() * 100\n",
        "    print(f\"\\n‚úÖ Precisi√≥n de BERT (Intent Recognition): {accuracy_nlu}%\")\n",
        "\n",
        "    # 2. M√©tricas de Satisfacci√≥n (CSAT)\n",
        "    promedio_csat = df_eval['Puntaje_CSAT'].mean()\n",
        "    print(f\"‚≠ê Satisfacci√≥n Promedio (CSAT): {promedio_csat}/5\")\n",
        "\n",
        "    # 3. Visualizaci√≥n\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Gr√°fico de Satisfacci√≥n\n",
        "    sns.countplot(x='Puntaje_CSAT', data=df_eval, ax=ax[0], palette=\"viridis\")\n",
        "    ax[0].set_title('Distribuci√≥n de Satisfacci√≥n del Cliente')\n",
        "\n",
        "    # Gr√°fico de Performance\n",
        "    sns.lineplot(x='Interacci√≥n', y='Tiempo_Respuesta_ms', data=df_eval, ax=ax[1], marker='o')\n",
        "    ax[1].set_title('Tiempo de Respuesta del Sistema (ms)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar el reporte\n",
        "mostrar_reporte_final()"
      ],
      "metadata": {
        "id": "zxeIfKJnwFQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finalizar_transaccion_con_encuesta():\n",
        "    print(\"\\nü§ñ Bot: ¬°Transacci√≥n completada con √©xito!\")\n",
        "    print(\"ü§ñ Bot: Del 1 al 5, ¬øqu√© tan satisfecho est√°s con mi servicio?\")\n",
        "    # En la interfaz de Gradio esto ser√≠a un slider o botones\n",
        "    print(\">> [Usuario selecciona 5 ‚≠ê]\")\n",
        "    print(\"ü§ñ Bot: ¬°Gracias! Tu feedback ayuda a mejorar mi modelo BERT.\")\n",
        "\n",
        "finalizar_transaccion_con_encuesta()"
      ],
      "metadata": {
        "id": "7fB_dZffwImc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}